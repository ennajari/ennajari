<img src="https://raw.githubusercontent.com/ABSphreak/ABSphreak/master/gifs/Hi.gif" width="30px"> **Hi there! I'm Abdellah Ennajari**

<div align="center">
  <img src="https://github.com/ennajari/ennajari/blob/main/Engineer.gif" alt="Profile Banner" width="700">

  <!-- Typing Animation -->
<a href="https://git.io/typing-svg" target="_blank" rel="noopener noreferrer">
  <img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&weight=700&size=26&pause=1000&color=6A5ACD&center=true&vCenter=true&width=600&lines=AI+%26+Deep+Learning+Engineer;Computer+Vision+Specialist;Generative+AI+Researcher;LLM+Prompt+Engineer;Multimodal+Systems+Developer;AI+Research+Enthusiast" alt="Typing SVG" />
</a>
  
  [![GitHub followers](https://img.shields.io/github/followers/ennajari?style=social)](https://github.com/ennajari)
  [![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/ennajari-abdellah)
  [![Portfolio](https://img.shields.io/badge/Portfolio-FF7139?style=for-the-badge&logo=Firefox-Browser&logoColor=white)](https://ennajari.github.io/AI_Engineer/)
  [![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:abdellahennajari2018@gmail.com)
  [![Hugging Face](https://img.shields.io/badge/🤗%20Hugging%20Face-FFD21F?style=for-the-badge&logo=huggingface&logoColor=black)](https://huggingface.co/)
</div>

<p align="center">
  <a href="#about-me">About Me</a> •
  <a href="#ai-specialization">AI Specialization</a> •
  <a href="#ai-projects">AI Projects</a> •
  <a href="#technical-skills">Technical Skills</a> •
  <a href="#ai-research">Research</a> •
  <a href="#github-stats">Stats</a> •
  <a href="#certifications">Certifications</a> •
  <a href="#connect-with-me">Connect</a>
</p>

---

## 🎓 AI & Deep Learning Engineer | ENIAD Berkane
I'm **Abdellah Ennajari**, a dedicated **AI Engineer** currently pursuing my degree at **ENIAD** (École Nationale d'Intelligence Artificielle et de Digital) in Berkane, Morocco. I specialize in developing advanced **Deep Learning models**, **Computer Vision systems**, and **Generative AI applications**. My expertise encompasses the complete AI development lifecycle, from data preprocessing and feature engineering to model deployment and monitoring.


<div align="center">
  <!-- Animated Waving Hand -->
  <img src="https://github.com/TheDudeThatCode/TheDudeThatCode/blob/master/Assets/Designer.gif" alt="Designer Gif" width="60">
  <img src="https://komarev.com/ghpvc/?username=ennajari&color=blueviolet&style=for-the-badge&label=PROFILE+VIEWS" alt="Profile Views">
  <img src="https://github.com/TheDudeThatCode/TheDudeThatCode/blob/master/Assets/Developer.gif" alt="Developer Gif" width="60">
</div>

---

<a id="about-me"></a>
## 🚀 About Me

```python
class AbdellahEnnajari:
    def __init__(self):
        self.name = "Abdellah Ennajari"
        self.role = "AI & Deep Learning Engineer"
        self.education = "ENIAD (École Nationale d'Intelligence Artificielle et de Digital), Berkane"
        self.location = "Morocco"
        self.tech_stack = {
            "deep_learning": ["TensorFlow", "PyTorch", "JAX", "Keras"],
            "computer_vision": ["OpenCV", "PyTorch3D", "Detectron2", "MediaPipe", "Kornia"],
            "nlp": ["Transformers", "Langchain", "SpaCy", "NLTK", "HuggingFace"],
            "generative_ai": ["Diffusion Models", "GANs", "Stable Diffusion", "RAG"],
            "mlops": ["Docker", "Kubernetes", "MLflow", "DVC", "Weights & Biases"],
            "3d_vision": ["Open3D", "PyTorch3D", "NeRF", "Point Cloud Processing", "3D Reconstruction"]
        }
        self.research_interests = ["Foundation Models", "Multimodal AI", "3D Vision", "Responsible AI", "MLOps"]
    
    def current_focus(self):
        return "Building scalable AI systems that bridge computer vision and natural language processing"

# Instantiate the AI Engineer
me = AbdellahEnnajari()
```

<a id="ai-specialization"></a>
## 🧠 AI Specialization Areas

<div align="center">
  <!-- AI Focus Areas Diagram -->
  
  ```mermaid
mindmap
  root((AI Engineering))
    Deep Learning
      CNN Architectures
      Transformers
      Self-Supervised Learning
      Neural Architecture Search
    Computer Vision
      3D Object Recognition
      Video Understanding
      Medical Image Analysis
      Neural Rendering
    Generative AI
      Diffusion Models
      Text-to-Image Systems
      RAG Architectures
      Multimodal Generation
    Foundation Models
      Fine-tuning Strategies
      Parameter-Efficient Training
      Prompt Engineering
      Knowledge Distillation
    MLOps
      Model Monitoring
      Continuous Deployment
      A/B Testing
      Resource Optimization
  ```


  ```mermaid
pie showData
    title Skills Breakdown: AI/ML Expertise
    "Deep Learning (CNN, RNN, LSTM, GRU)" : 25
    "Computer Vision (3D Recognition, Image Processing, ResNet, YOLO)" : 20
    "NLP (Text Analysis, Language Models, Embeddings, RoBERTa, XLNet)" : 20
    "Generative AI (GANs, Diffusion Models, LLMs, GPT, DALL·E)" : 25
    "MLOps (Deployment, CI/CD, Monitoring, MLflow, Docker, Kubernetes)" : 10
 ```
  
</div>

### Key Research Areas
- **3D Computer Vision**: Developing 3D object recognition systems with focus on medical applications
- **Multimodal Learning**: Creating systems that understand and generate across vision, language, and 3D domains
- **Responsible AI**: Implementing explainable AI techniques and fairness-aware algorithms
- **LLM Applications**: Building specialized RAG (Retrieval Augmented Generation) systems for domain-specific tasks
- **Foundation Model Deployment**: Optimizing large models for resource-constrained environments

<div align="center">
  <!-- AI Development Timeline -->
  
  ```mermaid
timeline
  title AI Engineering Journey
  2022 : Foundation in Mathematics & Computer Science
       : First deep learning projects with TensorFlow
  2023 : Specialized in AI & Data Science at ENIAD
       : Implemented Computer Vision for dental classification
       : Built first end-to-end ML pipeline
  2024 : Advanced 3D Vision Research (97% accuracy in dental modeling)
       : Developed multimodal RAG systems
       : Applied diffusion models to medical imaging
  2025 : Researching foundation models for 3D understanding
       : Building MLOps infrastructure for AI deployment
       : Exploring neural rendering for interactive applications
  ```
  
</div>

<a id="ai-projects"></a>
## 🔬 AI & Deep Learning Projects

<details open>
<summary><b>🦷 3D Dental Classification System (3D Smart Factory)</b></summary>
<br>
<img src="https://img.shields.io/badge/Domain-3D_Computer_Vision-blue">
<img src="https://img.shields.io/badge/Accuracy-97%25-success">
<img src="https://img.shields.io/badge/Models-PointNet++_&_3D_ConvNets-orange">

<div align="center">
  <img src="https://github.com/ennajari/ennajari/blob/main/200.gif" width="300">
</div>

**Technical Details:**
- Implemented a **hybrid 3D classification architecture** combining PointNet++ for point cloud processing and 3D ConvNets for volumetric analysis
- Designed custom data augmentation pipeline for 3D dental meshes (rotation, partial occlusion, point perturbation)
- Incorporated **attention mechanisms** to focus on critical tooth regions
- Applied **quantization** and **pruning** to optimize model for edge deployment
- Developed explainable AI visualization tools using **GradCAM for 3D** to highlight decision regions
- Achieved **35% faster inference** with minimal accuracy drop through knowledge distillation

**Tech Stack:** 
- **Models**: PointNet++, 3D-ResNet, MeshCNN
- **Libraries**: PyTorch3D, Open3D, NumPy, Matplotlib, Plotly
- **Deployment**: ONNX Runtime, TensorRT, Flask API

```mermaid
graph LR
    A[3D Scan Input] --> B[Mesh Processing]
    B --> C[Point Cloud Extraction]
    B --> D[Voxelization]
    C --> E[PointNet++ Feature Extractor]
    D --> F[3D-CNN Feature Extractor]
    E --> G[Feature Fusion]
    F --> G
    G --> H[Classification Head]
    H --> I[Tooth Type]
    H --> J[Pathology Detection]
    
    style A fill:#f9d5e5,stroke:#ff69b4
    style E fill:#d5f9e5,stroke:#00cc66
    style F fill:#d5e5f9,stroke:#3366cc
    style H fill:#f9e5d5,stroke:#cc6600
```
</details>

<details>
<summary><b>🔄 Multimodal RAG Chatbot for Academic Research</b></summary>
<br>
<img src="https://img.shields.io/badge/Domain-NLP_&_RAG-green">
<img src="https://img.shields.io/badge/Model-GPT_with_CLIP-purple">
<img src="https://img.shields.io/badge/Vector_DB-FAISS-blue">

<div align="center">
  <img src="https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExandzOGcxbTIweDJleTE5NDNyajRneHg5NXZlMTI0ZG1qeHNidTBleCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/L1R1tvI9svkIWwpVYr/giphy.gif" width="300">
</div>

**Technical Details:**
- Engineered a **multimodal retrieval system** capable of processing text, images, and PDFs using CLIP embeddings
- Implemented **hybrid search** combining semantic and sparse vectors for improved retrieval accuracy
- Built custom chunking algorithm with context-aware splitting for academic papers
- Integrated **re-ranking mechanisms** based on citation networks and semantic relevance
- Applied **query expansion** techniques to handle domain-specific terminologies
- Created evaluation framework measuring hallucination rates and factual accuracy

**Tech Stack:**
- **Models**: LangChain, HuggingFace Transformers, CLIP, FAISS
- **Vector DB**: FAISS with hybrid search
- **Backend**: FastAPI, Redis for caching
- **Frontend**: Streamlit, Gradio

```mermaid
sequenceDiagram
    participant U as User
    participant F as Frontend
    participant QP as Query Processor
    participant R as Retriever
    participant VDB as Vector DB
    participant LLM as Language Model
    
    U->>F: Query with Document/Image
    F->>QP: Process Input
    QP->>QP: Extract Keywords & Entities
    QP->>R: Optimized Query
    R->>VDB: Hybrid Search (Dense + Sparse)
    VDB-->>R: Top K Results
    R->>R: Re-rank Results
    R->>LLM: Query + Retrieved Context
    LLM-->>F: Generated Response with Citations
    F-->>U: Formatted Answer with Sources
```
</details>

<details>
<summary><b>🌐 Vision-Language Foundation Model for 3D Scene Understanding</b></summary>
<br>
<img src="https://img.shields.io/badge/Domain-Multimodal_Learning-orange">
<img src="https://img.shields.io/badge/Framework-PyTorch_3D-red">
<img src="https://img.shields.io/badge/Application-Scene_Understanding-blue">

<div align="center">
  <img src="https://github.com/ennajari/ennajari/blob/main/Nijol-Creative.gif" width="300">
</div>

**Technical Details:**
- Developed a foundation model connecting visual, textual, and 3D understanding
- Implemented **CLIP-based encoding** for both images and 3D point clouds
- Utilized **transformer architecture** with cross-attention between modalities
- Applied **contrastive learning objectives** for aligning text and 3D representations
- Engineered custom **prompt tuning techniques** for 3D reasoning tasks
- Designed novel data augmentation strategies for joint vision-language-3D training

**Tech Stack:**
- **Models**: Modified CLIP, Point-BERT, T5 Encoder
- **Libraries**: PyTorch3D, Transformers, OpenAI CLIP
- **3D Tools**: Open3D, PyTorch3D, Kaolin
- **Infrastructure**: PyTorch Lightning, Weights & Biases

```mermaid
graph TD
    A[Image Input] --> B[Vision Encoder]
    C[Text Input] --> D[Text Encoder]
    E[3D Point Cloud] --> F[3D Encoder]
    B --> G[Cross-Modal Transformer]
    D --> G
    F --> G
    G --> H[Joint Embedding Space]
    H --> I[3D Scene Understanding]
    H --> J[Image-Text-3D Retrieval]
    H --> K[3D Generation from Text]
    
    style B fill:#d1c4e9,stroke:#673ab7
    style D fill:#bbdefb,stroke:#2196f3
    style F fill:#c8e6c9,stroke:#4caf50
    style G fill:#ffecb3,stroke:#ffa000
    style H fill:#f8bbd0,stroke:#e91e63
```
</details>

<div align="center">
  <a href="https://github.com/ennajari?tab=repositories" target="_blank">
    <img src="https://img.shields.io/badge/View%20All%20AI%20Projects-181717?style=for-the-badge&logo=github&logoColor=white" alt="View All Projects">
  </a>
</div>

<a id="technical-skills"></a>
## 🔧 AI Technical Stack

<details open>
<summary><b>Deep Learning & AI Frameworks</b></summary>
<br>
<div>
  <img src="https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white">
  <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white">
  <img src="https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=keras&logoColor=white">
  <img src="https://img.shields.io/badge/JAX-0A2F5F?style=for-the-badge&logo=jax&logoColor=white">
  <img src="https://img.shields.io/badge/HuggingFace-FFD21F?style=for-the-badge&logo=huggingface&logoColor=black">
  <img src="https://img.shields.io/badge/LangChain-65B741?style=for-the-badge">
  <img src="https://img.shields.io/badge/PyTorch_Lightning-792EE5?style=for-the-badge&logo=pytorch-lightning&logoColor=white">
  <img src="https://img.shields.io/badge/Scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white">
  <img src="https://img.shields.io/badge/ONNX-005CED?style=for-the-badge&logo=onnx&logoColor=white">
  <img src="https://img.shields.io/badge/Stable_Diffusion-FF9D00?style=for-the-badge">
</div>
</details>

<details>
<summary><b>Computer Vision & 3D Vision</b></summary>
<br>
<div>
  <img src="https://img.shields.io/badge/OpenCV-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white">
  <img src="https://img.shields.io/badge/PyTorch3D-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white">
  <img src="https://img.shields.io/badge/Open3D-333333?style=for-the-badge">
  <img src="https://img.shields.io/badge/Detectron2-00C6B8?style=for-the-badge">
  <img src="https://img.shields.io/badge/MediaPipe-4285F4?style=for-the-badge&logo=google&logoColor=white">
  <img src="https://img.shields.io/badge/Kornia-FF007F?style=for-the-badge">
  <img src="https://img.shields.io/badge/NeRF-4B32C3?style=for-the-badge">
  <img src="https://img.shields.io/badge/CUDA-76B900?style=for-the-badge&logo=nvidia&logoColor=white">
  <img src="https://img.shields.io/badge/TensorRT-76B900?style=for-the-badge&logo=nvidia&logoColor=white">
  <img src="https://img.shields.io/badge/YOLO-00FFFF?style=for-the-badge">
</div>
</details>

<details>
<summary><b>NLP & Generative AI</b></summary>
<br>
<div>
  <img src="https://img.shields.io/badge/Transformers-FFD21F?style=for-the-badge&logo=huggingface&logoColor=black">
  <img src="https://img.shields.io/badge/SpaCy-09A3D5?style=for-the-badge">
  <img src="https://img.shields.io/badge/LangChain-65B741?style=for-the-badge">
  <img src="https://img.shields.io/badge/NLTK-76B900?style=for-the-badge">
  <img src="https://img.shields.io/badge/Diffusers-FF2D55?style=for-the-badge">
  <img src="https://img.shields.io/badge/RAG-6236FF?style=for-the-badge">
  <img src="https://img.shields.io/badge/CLIP-FFBA08?style=for-the-badge">
  <img src="https://img.shields.io/badge/BERT-2196F3?style=for-the-badge">
  <img src="https://img.shields.io/badge/GPT--3-412991?style=for-the-badge">
  <img src="https://img.shields.io/badge/Token_Classification-964B00?style=for-the-badge">
</div>
</details>

<details>
<summary><b>MLOps & AI Infrastructure</b></summary>
<br>
<div>
  <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white">
  <img src="https://img.shields.io/badge/Kubernetes-326CE5?style=for-the-badge&logo=kubernetes&logoColor=white">
  <img src="https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white">
  <img src="https://img.shields.io/badge/DVC-945DD6?style=for-the-badge&logo=dvc&logoColor=white">
  <img src="https://img.shields.io/badge/Weights_&_Biases-FFBE00?style=for-the-badge&logo=weightsandbiases&logoColor=black">
  <img src="https://img.shields.io/badge/AWS_SageMaker-232F3E?style=for-the-badge&logo=amazon-aws&logoColor=white">
  <img src="https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white">
  <img src="https://img.shields.io/badge/ONNX_Runtime-005CED?style=for-the-badge&logo=onnx&logoColor=white">
  <img src="https://img.shields.io/badge/Ray-028CF0?style=for-the-badge">
  <img src="https://img.shields.io/badge/BentoML-000000?style=for-the-badge">
</div>
</details>

<div align="center">
  <!-- AI Skills Specialization Chart -->
  
  ```mermaid
pie showData
    title "AI Expertise Distribution"
    "Deep Learning" : 30
    "Computer Vision & 3D Vision" : 25
    "Generative AI & LLMs" : 20
    "MLOps & Deployment" : 15
    "Research & Development" : 10
 ```
  
</div>

<a id="ai-research"></a>
## 📊 AI Research & Publications

<div align="center">
  <!-- Research Insights -->
  <table>
    <tr>
      <td width="33%" align="center">
        <a href="#">
          <img src="https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExcHppdmpwMHc5N2hxODY0Zjh6MHRnZm8wZjhtNXViOGRrZ2VmcHl6biZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/l0IylQoMkcbZUbtKw/giphy.gif" width="100%">
          <br>
          <strong>Explainable Computer Vision for Medical Applications</strong>
          <br>
          <small>Novel approaches to make 3D classification models interpretable for healthcare professionals</small>
        </a>
      </td>
      <td width="33%" align="center">
        <a href="#">
          <img src="https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExbzZxZ2hzNGdmZ2J1N213ZGE2cHd0Y3N5ZzNhenl1NHltOXYwN3NsaSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3oKIPEqDGUULpEU0aQ/giphy.gif" width="100%">
          <br>
          <strong>Advanced Diffusion Models for 3D Generation</strong>
          <br>
          <small>Extending text-to-image diffusion to 3D object generation with geometric constraints</small>
        </a>
      </td>
      <td width="33%" align="center">
        <a href="#">
          <img src="https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExemo2YjdxY3JhNTZkMHcwY2V4dnA3OG41Z29kbGVpbXYyYTAzNHN6ciZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/QN6NnhbgfOpoI/giphy.gif" width="100%">
          <br>
          <strong>Efficient Foundation Model Deployment</strong>
          <br>
          <small>Novel techniques for deploying large foundation models in resource-constrained environments</small>
        </a>
      </td>
    </tr>
  </table>
</div>

### Research Topics
- **Neural Rendering**: Exploring novel approaches to render 3D objects from sparse views
- **Parameter-Efficient Fine-Tuning**: Developing methods to adapt foundation models with minimal resources
- **Multimodal Retrieval**: Creating systems for cross-modal search across text, images, and 3D models
- **3D Foundation Models**: Building general-purpose representations for 3D understanding tasks

<a id="github-stats"></a>
## 📈 GitHub Analytics

<div align="center">
  <!-- Enhanced GitHub Stats with Animations -->
  <img src="https://github-readme-stats.vercel.app/api?username=ennajari&show_icons=true&theme=radical&border_radius=10&bg_color=45,000428,004e92&title_color=fff&text_color=fff&icon_color=fff&include_all_commits=true&count_private=true" height="180">
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=ennajari&layout=compact&theme=radical&border_radius=10&bg_color=45,000428,004e92&title_color=fff&text_color=fff&hide=html,css&langs_count=8" height="180">
</div>

<div align="center">
  <!-- Activity Graph -->
  <img src="https://github-readme-activity-graph.vercel.app/graph?username=ennajari&theme=react-dark&bg_color=000428&color=ffffff&line=6a5acd&point=ffffff&area=true&hide_border=true" width="800">
</div>

<a id="certifications"></a>
## 📜 AI Certifications & Training

<div>
  <a href="#"><img src="https://img.shields.io/badge/Deep_Learning_Specialization-DeepLearning.AI_(2024)-0056D2?style=for-the-badge&logo=coursera&logoColor=white"></a>
  <a href="#"><img src="https://img.shields.io/badge/TensorFlow_Developer-Google_(2024)-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white"></a>
  <a href="#"><img src="https://img.shields.io/badge/PyTorch_for_Deep_Learning-Udemy_(2023)-A435F0?style=for-the-badge&logo=pytorch&logoColor=white"></a>
  <a href="#"><img src="https://img.shields.io/badge/Machine_Learning_Engineering-MLOps_(2024)-00C7B7?style=for-the-badge"></a>
  <a href="#"><img src="https://img.shields.io/badge/Computer_Vision_Nanodegree-Udacity_(2023)-02B3E4?style=for-the-badge&logo=udacity&logoColor=white"></a>
  <a href="#"><img src="https://img.shields.io/badge/Generative_AI_with_LLMs-DeepLearning.AI_(2024)-0056D2?style=for-the-badge&logo=coursera&logoColor=white"></a>
  <a href="#"><img src="https://img.shields.io/badge/AWS_Machine_Learning-Amazon_(2025)-232F3E?style=for-the-badge&logo=amazon-aws&logoColor=white"></a>
</div>

<a id="connect-with-me"></a>
## 🔗 Connect With Me

<div>
  <a href="https://www.linkedin.com/in/ennajari-abdellah"><img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white"></a>
  <a href="https://github.com/ennajari"><img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white"></a>
  <a href="mailto:abdellahennajari2018@gmail.com"><img src="https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white"></a>
  <a href="https://huggingface.co/"><img src="https://img.shields.io/badge/HuggingFace-FFD21F?style=for-the-badge&logo=huggingface&logoColor=black"></a>
  <a href="https://scholar.google.com/"><img src="https://img.shields.io/badge/Google_Scholar-4285F4?style=for-the-badge&logo=google-scholar&logoColor=white"></a>
  <a href="#"><img src="https://img.shields.io/badge/Kaggle-20BEFF?style=for-the-badge&logo=kaggle&logoColor=white"></a>
</div>

<div align="center">
  <blockquote>
    <p><i>"AI is not just about algorithms and data—it's about creating systems that augment human intelligence and solve real-world problems."</i></p>
  </blockquote>
  
  <h3>Feel free to reach out for AI collaborations, research opportunities, or to discuss innovative applications of artificial intelligence! 🧠</h3>
  
  <img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=100&section=footer&animation=fadeIn" width="100%">
</div>
